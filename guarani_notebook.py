# %% [markdown]
# # Chatbot "O Guarani" - Execu√ß√£o e Teste Completo
# 
# Este notebook implementa e testa o sistema de chatbot especializado em "O Guarani" de Jos√© de Alencar,
# seguindo as 5 fases descritas no projeto original.

# %% [markdown]
# ## üìã Prepara√ß√£o Inicial

# %%
# Imports e configura√ß√µes iniciais
import sys
import os
from datetime import datetime

# Configura√ß√£o do hist√≥rico
historico_execucao = []

def log_execucao(fase, acao, resultado=None):
    """Registra cada passo da execu√ß√£o"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    entrada = {
        'timestamp': timestamp,
        'fase': fase,
        'acao': acao,
        'resultado': resultado,
        'status': 'OK' if resultado is not None else 'EXECUTANDO'
    }
    historico_execucao.append(entrada)
    print(f"[{timestamp}] {fase} - {acao} {('‚úÖ' if resultado else '‚è≥')}")

log_execucao("PREP", "Iniciando sistema de hist√≥rico")

# %% [markdown]
# ## üöÄ Fase 1: Prepara√ß√£o do Ambiente

# %%
log_execucao("FASE1", "Verificando depend√™ncias")

# Instala√ß√£o e importa√ß√£o das bibliotecas
try:
    import numpy as np
    import pandas as pd
    import re
    from typing import List, Dict, Tuple
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    import matplotlib.pyplot as plt
    log_execucao("FASE1", "Bibliotecas b√°sicas importadas", True)
except ImportError as e:
    log_execucao("FASE1", f"Erro na importa√ß√£o: {e}", False)

# %%
# Configura√ß√£o do NLTK
log_execucao("FASE1", "Configurando NLTK")

try:
    import nltk
    from nltk.corpus import stopwords
    from nltk.tokenize import word_tokenize, sent_tokenize
    from nltk.stem import RSLPStemmer
    
    # Downloads necess√°rios
    recursos_nltk = ['punkt', 'stopwords', 'rslp']
    for recurso in recursos_nltk:
        try:
            nltk.data.find(f'tokenizers/{recurso}' if recurso == 'punkt' else f'corpora/{recurso}')
        except LookupError:
            nltk.download(recurso, quiet=True)
    
    log_execucao("FASE1", "NLTK configurado com sucesso", True)
except Exception as e:
    log_execucao("FASE1", f"Erro no NLTK: {e}", False)

# %% [markdown]
# ## üìö Fase 2: Prepara√ß√£o e Processamento dos Dados

# %%
log_execucao("FASE2", "Carregando texto de O Guarani")

# Texto exemplo expandido da obra (em um projeto real, seria carregado de arquivo)
texto_guarani = """
O Guarani √© um romance de Jos√© de Alencar publicado em 1857. A hist√≥ria se passa no s√©culo XVII, 
durante a coloniza√ß√£o do Brasil. O protagonista √© Peri, um √≠ndio goitac√° de for√ßa excepcional 
e lealdade inquebrant√°vel.

Peri √© caracterizado por sua devo√ß√£o a Cec√≠lia, filha do fidalgo portugu√™s Dom Ant√¥nio de Mariz. 
A rela√ß√£o entre Peri e Ceci representa o encontro entre duas culturas: a ind√≠gena e a europeia.
Peri demonstra uma for√ßa f√≠sica impressionante e habilidades de ca√ßa excepcionais. Sua lealdade 
a Ceci √© absoluta, chegando ao ponto de sacrificar sua pr√≥pria vida por ela.

Dom Ant√¥nio de Mariz √© um nobre portugu√™s que se estabeleceu no Brasil com sua fam√≠lia. 
Ele possui um castelo fortificado √†s margens do rio Paquequer, onde vive com sua esposa, 
filhos e alguns agregados. Dom Ant√¥nio √© um homem honrado que respeita Peri pela sua nobreza de car√°ter.

Cec√≠lia, conhecida como Ceci, √© a filha de Dom Ant√¥nio de Mariz. Ela √© descrita como uma jovem 
bela e bondosa, que desenvolve um sentimento especial por Peri. Ceci representa a pureza e 
a inoc√™ncia, contrastando com a rudeza do ambiente colonial.

A obra retrata os conflitos entre diferentes grupos: os portugueses colonizadores, 
os √≠ndios aimor√©s (inimigos de Peri) e os aventureiros que buscam ouro na regi√£o.
Os aimor√©s s√£o apresentados como uma tribo guerreira e feroz, representando uma amea√ßa 
constante aos habitantes do castelo.

√Ålvaro √© um jovem portugu√™s, primo de Cec√≠lia, que tamb√©m habita o castelo. 
Ele representa o europeu civilizado, contrastando com a natureza selvagem de Peri.
√Ålvaro √© corajoso e leal, desenvolvendo uma rela√ß√£o de respeito m√∫tuo com o √≠ndio.

Isabel √© irm√£ de Cec√≠lia, uma jovem impetuosa que se apaixona por √Ålvaro. 
Sua hist√≥ria pessoal adiciona complexidade aos relacionamentos na narrativa.
Isabel √© caracterizada por sua personalidade forte e determinada.

A natureza brasileira √© quase um personagem na obra, sendo descrita com detalhes 
que evidenciam a vis√£o rom√¢ntica de Alencar sobre a paisagem nacional.
As descri√ß√µes incluem a exuberante floresta tropical, os rios caudalosos e 
a fauna diversificada da regi√£o.

O romance explora temas como o amor imposs√≠vel entre Peri e Ceci, 
a lealdade, o sacrif√≠cio e o choque entre civiliza√ß√µes. Alencar retrata 
o √≠ndio como um "bom selvagem", idealizando sua pureza moral.

A linguagem de Alencar mescla o portugu√™s culto com express√µes que buscam 
retratar a fala dos personagens ind√≠genas, criando um estilo √∫nico.
O autor utiliza um registro elevado, caracter√≠stico do Romantismo brasileiro.

O enredo culmina com a destrui√ß√£o do castelo e a fuga de Peri e Ceci,
simbolizando o nascimento de uma nova ra√ßa brasileira atrav√©s da uni√£o
entre o elemento ind√≠gena e o europeu.
"""

print(f"Texto carregado: {len(texto_guarani)} caracteres")
print(f"Aproximadamente {len(texto_guarani.split())} palavras")
log_execucao("FASE2", "Texto carregado com sucesso", len(texto_guarani))

# %%
log_execucao("FASE2", "Iniciando pr√©-processamento")

# Classe para processamento de texto
class ProcessadorTexto:
    def __init__(self):
        self.stemmer = RSLPStemmer()
        self.stop_words = set(stopwords.words('portuguese'))
        
    def limpar_texto(self, texto):
        """Limpa e normaliza o texto"""
        # Remove quebras de linha excessivas
        texto = re.sub(r'\n+', ' ', texto)
        # Remove espa√ßos m√∫ltiplos
        texto = re.sub(r'\s+', ' ', texto)
        # Mant√©m apenas caracteres alfanum√©ricos e pontua√ß√£o b√°sica
        texto = re.sub(r'[^\w\s.,!?;:]', '', texto)
        return texto.strip()
    
    def preprocessar(self, texto):
        """Aplica pr√©-processamento completo"""
        # Tokeniza√ß√£o
        tokens = word_tokenize(texto.lower(), language='portuguese')
        
        # Filtragem: remove stopwords e tokens curtos
        tokens_filtrados = [
            token for token in tokens 
            if (token not in self.stop_words and 
                len(token) > 2 and 
                token.isalpha())
        ]
        
        # Stemming
        tokens_stemmed = [self.stemmer.stem(token) for token in tokens_filtrados]
        
        return ' '.join(tokens_stemmed)
    
    def criar_chunks(self, texto, tamanho_chunk=200, sobreposicao=0.5):
        """Cria chunks de texto com sobreposi√ß√£o"""
        sentencas = sent_tokenize(texto, language='portuguese')
        chunks = []
        
        chunk_atual = []
        contador_palavras = 0
        
        for sentenca in sentencas:
            palavras = sentenca.split()
            
            if contador_palavras + len(palavras) <= tamanho_chunk:
                chunk_atual.append(sentenca)
                contador_palavras += len(palavras)
            else:
                if chunk_atual:
                    chunks.append(' '.join(chunk_atual))
                
                # Aplicar sobreposi√ß√£o
                num_overlap = int(len(chunk_atual) * sobreposicao)
                chunk_atual = chunk_atual[-num_overlap:] if num_overlap > 0 else []
                chunk_atual.append(sentenca)
                contador_palavras = sum(len(s.split()) for s in chunk_atual)
        
        # Adicionar √∫ltimo chunk
        if chunk_atual:
            chunks.append(' '.join(chunk_atual))
        
        return chunks

# Instanciar processador
processador = ProcessadorTexto()

# Limpar texto
texto_limpo = processador.limpar_texto(texto_guarani)
log_execucao("FASE2", "Texto limpo", len(texto_limpo))

# Criar chunks
chunks = processador.criar_chunks(texto_limpo)
print(f"Criados {len(chunks)} chunks de texto")
log_execucao("FASE2", f"Chunks criados: {len(chunks)}", len(chunks))

# %%
# Visualizar exemplos de chunks
log_execucao("FASE2", "Exibindo exemplos de chunks")

print("üìã EXEMPLOS DE CHUNKS CRIADOS:")
print("=" * 60)

for i, chunk in enumerate(chunks[:3]):  # Mostra apenas os 3 primeiros
    print(f"\nüîπ Chunk {i+1}:")
    print(f"   Tamanho: {len(chunk.split())} palavras")
    print(f"   Texto: {chunk[:150]}...")

# %%
# Pr√©-processar chunks
log_execucao("FASE2", "Pr√©-processando chunks")

chunks_processados = []
for i, chunk in enumerate(chunks):
    chunk_processado = processador.preprocessar(chunk)
    chunks_processados.append(chunk_processado)

print(f"Chunks pr√©-processados: {len(chunks_processados)}")
log_execucao("FASE2", "Pr√©-processamento conclu√≠do", len(chunks_processados))

# Exemplo de chunk antes e depois do processamento
print("\nüìä EXEMPLO DE PROCESSAMENTO:")
print("Antes:", chunks[0][:200] + "...")
print("Depois:", chunks_processados[0][:200] + "...")

# %% [markdown]
# ## üóÑÔ∏è Fase 3: Armazenamento e Indexa√ß√£o

# %%
log_execucao("FASE3", "Criando vectorizador TF-IDF")

# Configurar vectorizador TF-IDF
vectorizador = TfidfVectorizer(
    max_features=1000,  # M√°ximo de features
    ngram_range=(1, 2),  # Uni e bigramas
    min_df=1,  # Frequ√™ncia m√≠nima de documento
    max_df=0.95  # Frequ√™ncia m√°xima de documento
)

# Treinar vectorizador e criar matriz de vetores
matriz_vetores = vectorizador.fit_transform(chunks_processados)

print(f"Matriz de vetores: {matriz_vetores.shape}")
print(f"Vocabul√°rio: {len(vectorizador.vocabulary_)} termos")

log_execucao("FASE3", "Vetoriza√ß√£o conclu√≠da", matriz_vetores.shape[0])

# %%
# Analisar vocabul√°rio mais importante
log_execucao("FASE3", "Analisando vocabul√°rio")

# Obter nomes das features
feature_names = vectorizador.get_feature_names_out()

# Calcular pontua√ß√£o TF-IDF m√©dia para cada termo
pontuacoes_medias = np.array(matriz_vetores.mean(axis=0)).flatten()

# Criar DataFrame para an√°lise
vocab_df = pd.DataFrame({
    'termo': feature_names,
    'tfidf_medio': pontuacoes_medias
}).sort_values('tfidf_medio', ascending=False)

print("üîù TOP 10 TERMOS MAIS RELEVANTES:")
print(vocab_df.head(10))

log_execucao("FASE3", "An√°lise de vocabul√°rio conclu√≠da", len(feature_names))

# %% [markdown]
# ## üîç Fase 4: Sistema de Busca e Resposta

# %%
log_execucao("FASE4", "Implementando sistema de busca")

class SistemaBusca:
    def __init__(self, chunks_originais, chunks_processados, vectorizador, matriz_vetores):
        self.chunks_originais = chunks_originais
        self.chunks_processados = chunks_processados
        self.vectorizador = vectorizador
        self.matriz_vetores = matriz_vetores
        self.processador = ProcessadorTexto()
        self.limiar_similaridade = 0.1
        self.top_k = 3
    
    def buscar(self, pergunta):
        """Busca chunks relevantes para a pergunta"""
        # Pr√©-processar pergunta
        pergunta_processada = self.processador.preprocessar(pergunta)
        
        # Vetorizar pergunta
        vetor_pergunta = self.vectorizador.transform([pergunta_processada])
        
        # Calcular similaridades
        similaridades = cosine_similarity(vetor_pergunta, self.matriz_vetores).flatten()
        
        # Filtrar e ordenar resultados
        resultados = []
        for i, sim in enumerate(similaridades):
            if sim >= self.limiar_similaridade:
                resultados.append({
                    'chunk_id': i,
                    'texto_original': self.chunks_originais[i],
                    'similaridade': sim
                })
        
        # Ordenar por similaridade
        resultados.sort(key=lambda x: x['similaridade'], reverse=True)
        
        return resultados[:self.top_k]
    
    def gerar_resposta(self, pergunta, resultados):
        """Gera resposta baseada nos resultados da busca"""
        if not resultados:
            return "Desculpe, n√£o encontrei informa√ß√µes relevantes sobre sua pergunta no texto de 'O Guarani'."
        
        # Usar o chunk mais relevante como base da resposta
        melhor_resultado = resultados[0]
        texto_base = melhor_resultado['texto_original']
        confianca = melhor_resultado['similaridade']
        
        # Formata√ß√£o da resposta
        resposta = f"Com base em 'O Guarani':\n\n{texto_base}"
        
        # Adicionar indicador de confian√ßa
        if confianca > 0.5:
            resposta += "\n\n(Resposta com alta confian√ßa)"
        elif confianca > 0.3:
            resposta += "\n\n(Resposta com confian√ßa moderada)"
        else:
            resposta += "\n\n(Resposta com baixa confian√ßa)"
        
        return resposta

# Instanciar sistema de busca
sistema_busca = SistemaBusca(chunks, chunks_processados, vectorizador, matriz_vetores)

log_execucao("FASE4", "Sistema de busca implementado", True)

# %%
# Testar sistema com perguntas exemplo
log_execucao("FASE4", "Testando sistema com perguntas exemplo")

perguntas_teste = [
    "Quem √© Peri?",
    "Fale sobre Cec√≠lia",
    "Qual √© o enredo de O Guarani?",
    "Quem s√£o os personagens principais?",
    "Onde se passa a hist√≥ria?",
    "Como √© descrita a natureza no livro?"
]

resultados_teste = []

print("üß™ TESTE DO SISTEMA DE BUSCA")
print("=" * 50)

for pergunta in perguntas_teste:
    print(f"\n‚ùì Pergunta: {pergunta}")
    
    # Buscar
    resultados = sistema_busca.buscar(pergunta)
    
    # Gerar resposta
    resposta = sistema_busca.gerar_resposta(pergunta, resultados)
    
    # Exibir resultado resumido
    if resultados:
        sim_max = max([r['similaridade'] for r in resultados])
        print(f"üéØ Similaridade m√°xima: {sim_max:.3f}")
        print(f"üìù Chunks encontrados: {len(resultados)}")
        print(f"ü§ñ Resposta: {resposta[:100]}...")
    else:
        print("‚ùå Nenhum resultado encontrado")
    
    # Armazenar para hist√≥rico
    resultados_teste.append({
        'pergunta': pergunta,
        'resposta': resposta,
        'num_resultados': len(resultados),
        'similaridade_max': max([r['similaridade'] for r in resultados]) if resultados else 0
    })

log_execucao("FASE4", f"Teste conclu√≠do com {len(perguntas_teste)} perguntas", len(perguntas_teste))

# %% [markdown]
# ## üéØ Fase 5: Interface e Demonstra√ß√£o

# %%
log_execucao("FASE5", "Preparando interface de demonstra√ß√£o")

def demonstrar_consulta_detalhada(pergunta):
    """Demonstra uma consulta com detalhes completos"""
    print(f"üîç AN√ÅLISE DETALHADA DA CONSULTA")
    print("=" * 60)
    print(f"Pergunta: {pergunta}")
    print()
    
    # Buscar resultados
    resultados = sistema_busca.buscar(pergunta)
    
    # Mostrar processo de busca
    pergunta_processada = sistema_busca.processador.preprocessar(pergunta)
    print(f"Pergunta processada: {pergunta_processada}")
    print()
    
    # Mostrar resultados encontrados
    print(f"Resultados encontrados: {len(resultados)}")
    print()
    
    for i, resultado in enumerate(resultados):
        print(f"üìÑ Resultado {i+1}:")
        print(f"   Similaridade: {resultado['similaridade']:.3f}")
        print(f"   Texto: {resultado['texto_original'][:200]}...")
        print()
    
    # Gerar e mostrar resposta final
    resposta = sistema_busca.gerar_resposta(pergunta, resultados)
    print("ü§ñ RESPOSTA FINAL:")
    print("=" * 40)
    print(resposta)
    
    return resposta

# Demonstra√ß√£o com pergunta espec√≠fica
pergunta_demo = "Quem √© Peri e quais s√£o suas principais caracter√≠sticas?"
resposta_demo = demonstrar_consulta_detalhada(pergunta_demo)

log_execucao("FASE5", "Demonstra√ß√£o detalhada conclu√≠da", True)

# %% [markdown]
# ## üìä An√°lise de Performance e Hist√≥rico

# %%
log_execucao("AN√ÅLISE", "Gerando estat√≠sticas do sistema")

# Estat√≠sticas gerais
print("üìà ESTAT√çSTICAS DO SISTEMA")
print("=" * 50)
print(f"Total de chunks: {len(chunks)}")
print(f"Vocabul√°rio: {len(vectorizador.vocabulary_)} termos")
print(f"Dimens√µes da matriz: {matriz_vetores.shape}")
print(f"Densidade da matriz: {matriz_vetores.nnz / (matriz_vetores.shape[0] * matriz_vetores.shape[1]):.3f}")

# An√°lise dos testes
if resultados_teste:
    similaridades = [r['similaridade_max'] for r in resultados_teste]
    print(f"\nPerguntas testadas: {len(resultados_teste)}")
    print(f"Similaridade m√©dia: {np.mean(similaridades):.3f}")
    print(f"Similaridade m√°xima: {np.max(similaridades):.3f}")
    print(f"Similaridade m√≠nima: {np.min(similaridades):.3f}")

log_execucao("AN√ÅLISE", "Estat√≠sticas geradas", len(resultados_teste))

# %%
# Visualiza√ß√£o das similaridades
log_execucao("AN√ÅLISE", "Criando visualiza√ß√µes")

if resultados_teste:
    plt.figure(figsize=(12, 6))
    
    # Gr√°fico de barras das similaridades
    plt.subplot(1, 2, 1)
    perguntas_abrev = [r['pergunta'][:20] + "..." for r in resultados_teste]
    similaridades = [r['similaridade_max'] for r in resultados_teste]
    
    plt.bar(range(len(similaridades)), similaridades)
    plt.title('Similaridade por Pergunta')
    plt.xlabel('Pergunta')
    plt.ylabel('Similaridade M√°xima')
    plt.xticks(range(len(perguntas_abrev)), perguntas_abrev, rotation=45, ha='right')
    
    # Histograma das similaridades
    plt.subplot(1, 2, 2)
    plt.hist(similaridades, bins=5, alpha=0.7, color='skyblue', edgecolor='black')
    plt.title('Distribui√ß√£o das Similaridades')
    plt.xlabel('Similaridade')
    plt.ylabel('Frequ√™ncia')
    
    plt.tight_layout()
    plt.show()
    
    log_execucao("AN√ÅLISE", "Visualiza√ß√µes criadas", True)

# %%
# Hist√≥rico completo de execu√ß√£o
log_execucao("HIST√ìRICO", "Compilando hist√≥rico completo")

print("üìã HIST√ìRICO COMPLETO DE EXECU√á√ÉO")
print("=" * 70)

# Agrupar por fase
fases = {}
for entrada in historico_execucao:
    fase = entrada['fase']
    if fase not in fases:
        fases[fase] = []
    fases[fase].append(entrada)

# Exibir por fase
for fase, entradas in fases.items():
    print(f"\nüîπ {fase}:")
    for entrada in entradas:
        status = "‚úÖ" if entrada['status'] == 'OK' else "‚è≥" if entrada['status'] == 'EXECUTANDO' else "‚ùå"
        resultado_texto = f" ‚Üí {entrada['resultado']}" if entrada['resultado'] is not None else ""
        print(f"   [{entrada['timestamp']}] {status} {entrada['acao']}{resultado_texto}")

# Resumo final
total_acoes = len(historico_execucao)
acoes_ok = len([e for e in historico_execucao if e['status'] == 'OK'])
percentual_sucesso = (acoes_ok / total_acoes) * 100 if total_acoes > 0 else 0

print(f"\nüìä RESUMO FINAL:")
print(f"   Total de a√ß√µes: {total_acoes}")
print(f"   A√ß√µes bem-sucedidas: {acoes_ok}")
print(f"   Taxa de sucesso: {percentual_sucesso:.1f}%")

log_execucao("HIST√ìRICO", "Hist√≥rico compilado", total_acoes)

# %% [markdown]
# ## üéâ Sistema Completo Implementado
# 
# O chatbot "O Guarani" foi implementado com sucesso seguindo todas as 5 fases:
# 
# 1. ‚úÖ **Prepara√ß√£o do Ambiente**: Bibliotecas configuradas
# 2. ‚úÖ **Processamento dos Dados**: Texto limpo e segmentado em chunks
# 3. ‚úÖ **Armazenamento e Indexa√ß√£o**: Vetores TF-IDF criados
# 4. ‚úÖ **Sistema de Busca**: Busca por similaridade implementada
# 5. ‚úÖ **Interface**: Sistema testado e demonstrado
# 
# ### Pr√≥ximos Passos:
# - Expandir base de texto com obra completa
# - Implementar Word2Vec para melhor sem√¢ntica
# - Adicionar interface web com Streamlit
# - Melhorar gera√ß√£o de respostas com templates
# - Adicionar avalia√ß√£o autom√°tica de qualidade

print("\nüéâ SISTEMA CHATBOT 'O GUARANI' IMPLEMENTADO COM SUCESSO!")
print("Todas as fases foram executadas e testadas.")
print("Hist√≥rico completo de execu√ß√£o mantido e dispon√≠vel.")
