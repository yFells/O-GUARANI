# %% [markdown]
# # Chatbot "O Guarani" - ExecuÃ§Ã£o e Teste Completo
# 
# Este notebook implementa e testa o sistema de chatbot especializado em "O Guarani" de JosÃ© de Alencar,
# seguindo as 5 fases descritas no projeto original.

# %% [markdown]
# ## ðŸ“‹ PreparaÃ§Ã£o Inicial

# %%
# Imports e configuraÃ§Ãµes iniciais
import sys
import os
from datetime import datetime

# ConfiguraÃ§Ã£o do histÃ³rico
historico_execucao = []

def log_execucao(fase, acao, resultado=None):
    """Registra cada passo da execuÃ§Ã£o"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    entrada = {
        'timestamp': timestamp,
        'fase': fase,
        'acao': acao,
        'resultado': resultado,
        'status': 'OK' if resultado is not None else 'EXECUTANDO'
    }
    historico_execucao.append(entrada)
    print(f"[{timestamp}] {fase} - {acao} {('âœ…' if resultado else 'â³')}")

log_execucao("PREP", "Iniciando sistema de histÃ³rico")

# %% [markdown]
# ## ðŸš€ Fase 1: PreparaÃ§Ã£o do Ambiente

# %%
log_execucao("FASE1", "Verificando dependÃªncias")

# InstalaÃ§Ã£o e importaÃ§Ã£o das bibliotecas
try:
    import numpy as np
    import pandas as pd
    import re
    from typing import List, Dict, Tuple
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    import matplotlib.pyplot as plt
    log_execucao("FASE1", "Bibliotecas bÃ¡sicas importadas", True)
except ImportError as e:
    log_execucao("FASE1", f"Erro na importaÃ§Ã£o: {e}", False)

# %%
# ConfiguraÃ§Ã£o do NLTK
log_execucao("FASE1", "Configurando NLTK")

try:
    import nltk
    from nltk.corpus import stopwords
    from nltk.tokenize import word_tokenize, sent_tokenize
    from nltk.stem import RSLPStemmer
    
    # Downloads necessÃ¡rios
    recursos_nltk = ['punkt', 'stopwords', 'rslp']
    for recurso in recursos_nltk:
        try:
            nltk.data.find(f'tokenizers/{recurso}' if recurso == 'punkt' else f'corpora/{recurso}')
        except LookupError:
            nltk.download(recurso, quiet=True)
    
    log_execucao("FASE1", "NLTK configurado com sucesso", True)
except Exception as e:
    log_execucao("FASE1", f"Erro no NLTK: {e}", False)

# %% [markdown]
# ## ðŸ“š Fase 2: PreparaÃ§Ã£o e Processamento dos Dados

# %%
log_execucao("FASE2", "Carregando texto de O Guarani")

# Texto exemplo expandido da obra (em um projeto real, seria carregado de arquivo)
texto_guarani = """
O Guarani Ã© um romance de JosÃ© de Alencar publicado em 1857. A histÃ³ria se passa no sÃ©culo XVII, 
durante a colonizaÃ§Ã£o do Brasil. O protagonista Ã© Peri, um Ã­ndio goitacÃ¡ de forÃ§a excepcional 
e lealdade inquebrantÃ¡vel.

Peri Ã© caracterizado por sua devoÃ§Ã£o a CecÃ­lia, filha do fidalgo portuguÃªs Dom AntÃ´nio de Mariz. 
A relaÃ§Ã£o entre Peri e Ceci representa o encontro entre duas culturas: a indÃ­gena e a europeia.
Peri demonstra uma forÃ§a fÃ­sica impressionante e habilidades de caÃ§a excepcionais. Sua lealdade 
a Ceci Ã© absoluta, chegando ao ponto de sacrificar sua prÃ³pria vida por ela.

Dom AntÃ´nio de Mariz Ã© um nobre portuguÃªs que se estabeleceu no Brasil com sua famÃ­lia. 
Ele possui um castelo fortificado Ã s margens do rio Paquequer, onde vive com sua esposa, 
filhos e alguns agregados. Dom AntÃ´nio Ã© um homem honrado que respeita Peri pela sua nobreza de carÃ¡ter.

CecÃ­lia, conhecida como Ceci, Ã© a filha de Dom AntÃ´nio de Mariz. Ela Ã© descrita como uma jovem 
bela e bondosa, que desenvolve um sentimento especial por Peri. Ceci representa a pureza e 
a inocÃªncia, contrastando com a rudeza do ambiente colonial.

A obra retrata os conflitos entre diferentes grupos: os portugueses colonizadores, 
os Ã­ndios aimorÃ©s (inimigos de Peri) e os aventureiros que buscam ouro na regiÃ£o.
Os aimorÃ©s sÃ£o apresentados como uma tribo guerreira e feroz, representando uma ameaÃ§a 
constante aos habitantes do castelo.

Ãlvaro Ã© um jovem portuguÃªs, primo de CecÃ­lia, que tambÃ©m habita o castelo. 
Ele representa o europeu civilizado, contrastando com a natureza selvagem de Peri.
Ãlvaro Ã© corajoso e leal, desenvolvendo uma relaÃ§Ã£o de respeito mÃºtuo com o Ã­ndio.

Isabel Ã© irmÃ£ de CecÃ­lia, uma jovem impetuosa que se apaixona por Ãlvaro. 
Sua histÃ³ria pessoal adiciona complexidade aos relacionamentos na narrativa.
Isabel Ã© caracterizada por sua personalidade forte e determinada.

A natureza brasileira Ã© quase um personagem na obra, sendo descrita com detalhes 
que evidenciam a visÃ£o romÃ¢ntica de Alencar sobre a paisagem nacional.
As descriÃ§Ãµes incluem a exuberante floresta tropical, os rios caudalosos e 
a fauna diversificada da regiÃ£o.

O romance explora temas como o amor impossÃ­vel entre Peri e Ceci, 
a lealdade, o sacrifÃ­cio e o choque entre civilizaÃ§Ãµes. Alencar retrata 
o Ã­ndio como um "bom selvagem", idealizando sua pureza moral.

A linguagem de Alencar mescla o portuguÃªs culto com expressÃµes que buscam 
retratar a fala dos personagens indÃ­genas, criando um estilo Ãºnico.
O autor utiliza um registro elevado, caracterÃ­stico do Romantismo brasileiro.

O enredo culmina com a destruiÃ§Ã£o do castelo e a fuga de Peri e Ceci,
simbolizando o nascimento de uma nova raÃ§a brasileira atravÃ©s da uniÃ£o
entre o elemento indÃ­gena e o europeu.
"""

print(f"Texto carregado: {len(texto_guarani)} caracteres")
print(f"Aproximadamente {len(texto_guarani.split())} palavras")
log_execucao("FASE2", "Texto carregado com sucesso", len(texto_guarani))

# %%
log_execucao("FASE2", "Iniciando prÃ©-processamento")

# Classe para processamento de texto
class ProcessadorTexto:
    def __init__(self):
        self.stemmer = RSLPStemmer()
        self.stop_words = set(stopwords.words('portuguese'))
        
    def limpar_texto(self, texto):
        """Limpa e normaliza o texto"""
        # Remove quebras de linha excessivas
        texto = re.sub(r'\n+', ' ', texto)
        # Remove espaÃ§os mÃºltiplos
        texto = re.sub(r'\s+', ' ', texto)
        # MantÃ©m apenas caracteres alfanumÃ©ricos e pontuaÃ§Ã£o bÃ¡sica
        texto = re.sub(r'[^\w\s.,!?;:]', '', texto)
        return texto.strip()
    
    def preprocessar(self, texto):
        """Aplica prÃ©-processamento completo"""
        # TokenizaÃ§Ã£o
        tokens = word_tokenize(texto.lower(), language='portuguese')
        
        # Filtragem: remove stopwords e tokens curtos
        tokens_filtrados = [
            token for token in tokens 
            if (token not in self.stop_words and 
                len(token) > 2 and 
                token.isalpha())
        ]
        
        # Stemming
        tokens_stemmed = [self.stemmer.stem(token) for token in tokens_filtrados]
        
        return ' '.join(tokens_stemmed)
    
    def criar_chunks(self, texto, tamanho_chunk=200, sobreposicao=0.5):
        """Cria chunks de texto com sobreposiÃ§Ã£o"""
        sentencas = sent_tokenize(texto, language='portuguese')
        chunks = []
        
        chunk_atual = []
        contador_palavras = 0
        
        for sentenca in sentencas:
            palavras = sentenca.split()
            
            if contador_palavras + len(palavras) <= tamanho_chunk:
                chunk_atual.append(sentenca)
                contador_palavras += len(palavras)
            else:
                if chunk_atual:
                    chunks.append(' '.join(chunk_atual))
                
                # Aplicar sobreposiÃ§Ã£o
                num_overlap = int(len(chunk_atual) * sobreposicao)
                chunk_atual = chunk_atual[-num_overlap:] if num_overlap > 0 else []
                chunk_atual.append(sentenca)
                contador_palavras = sum(len(s.split()) for s in chunk_atual)
        
        # Adicionar Ãºltimo chunk
        if chunk_atual:
            chunks.append(' '.join(chunk_atual))
        
        return chunks

# Instanciar processador
processador = ProcessadorTexto()

# Limpar texto
texto_limpo = processador.limpar_texto(texto_guarani)
log_execucao("FASE2", "Texto limpo", len(texto_limpo))

# Criar chunks
chunks = processador.criar_chunks(texto_limpo)
print(f"Criados {len(chunks)} chunks de texto")
log_execucao("FASE2", f"Chunks criados: {len(chunks)}", len(chunks))

# %%
# Visualizar exemplos de chunks
log_execucao("FASE2", "Exibindo exemplos de chunks")

print("ðŸ“‹ EXEMPLOS DE CHUNKS CRIADOS:")
print("=" * 60)

for i, chunk in enumerate(chunks[:3]):  # Mostra apenas os 3 primeiros
    print(f"\nðŸ”¹ Chunk {i+1}:")
    print(f"   Tamanho: {len(chunk.split())} palavras")
    print(f"   Texto: {chunk[:150]}...")

# %%
# PrÃ©-processar chunks
log_execucao("FASE2", "PrÃ©-processando chunks")

chunks_processados = []
for i, chunk in enumerate(chunks):
    chunk_processado = processador.preprocessar(chunk)
    chunks_processados.append(chunk_processado)

print(f"Chunks prÃ©-processados: {len(chunks_processados)}")
log_execucao("FASE2", "PrÃ©-processamento concluÃ­do", len(chunks_processados))

# Exemplo de chunk antes e depois do processamento
print("\nðŸ“Š EXEMPLO DE PROCESSAMENTO:")
print("Antes:", chunks[0][:200] + "...")
print("Depois:", chunks_processados[0][:200] + "...")

# %% [markdown]
# ## ðŸ—„ï¸ Fase 3: Armazenamento e IndexaÃ§Ã£o

# %%
log_execucao("FASE3", "Criando vectorizador TF-IDF")

# Configurar vectorizador TF-IDF
vectorizador = TfidfVectorizer(
    max_features=1000,  # MÃ¡ximo de features
    ngram_range=(1, 2),  # Uni e bigramas
    min_df=1,  # FrequÃªncia mÃ­nima de documento
    max_df=0.95  # FrequÃªncia mÃ¡xima de documento
)

# Treinar vectorizador e criar matriz de vetores
matriz_vetores = vectorizador.fit_transform(chunks_processados)

print(f"Matriz de vetores: {matriz_vetores.shape}")
print(f"VocabulÃ¡rio: {len(vectorizador.vocabulary_)} termos")

log_execucao("FASE3", "VetorizaÃ§Ã£o concluÃ­da", matriz_vetores.shape[0])

# %%
# Analisar vocabulÃ¡rio mais importante
log_execucao("FASE3", "Analisando vocabulÃ¡rio")

# Obter nomes das features
feature_names = vectorizador.get_feature_names_out()

# Calcular pontuaÃ§Ã£o TF-IDF mÃ©dia para cada termo
pontuacoes_medias = np.array(matriz_vetores.mean(axis=0)).flatten()

# Criar DataFrame para anÃ¡lise
vocab_df = pd.DataFrame({
    'termo': feature_names,
    'tfidf_medio': pontuacoes_medias
}).sort_values('tfidf_medio', ascending=False)

print("ðŸ” TOP 10 TERMOS MAIS RELEVANTES:")
print(vocab_df.head(10))

log_execucao("FASE3", "AnÃ¡lise de vocabulÃ¡rio concluÃ­da", len(feature_names))

# %% [markdown]
# ## ðŸ” Fase 4: Sistema de Busca e Resposta

# %%
log_execucao("FASE4", "Implementando sistema de busca")

class SistemaBusca:
    def __init__(self, chunks_originais, chunks_processados, vectorizador, matriz_vetores):
        self.chunks_originais = chunks_originais
        self.chunks_processados = chunks_processados
        self.vectorizador = vectorizador
        self.matriz_vetores = matriz_vetores
        self.processador = ProcessadorTexto()
        self.limiar_similaridade = 0.1
        self.top_k = 3
    
    def buscar(self, pergunta):
        """Busca chunks relevantes para a pergunta"""
        # PrÃ©-processar pergunta
        pergunta_processada = self.processador.preprocessar(pergunta)
        
        # Vetorizar pergunta
        vetor_pergunta = self.vectorizador.transform([pergunta_processada])
        
        # Calcular similaridades
        similaridades = cosine_similarity(vetor_pergunta, self.matriz_vetores).flatten()
        
        # Filtrar e ordenar resultados
        resultados = []
        for i, sim in enumerate(similaridades):
            if sim >= self.limiar_similaridade:
                resultados.append({
                    'chunk_id': i,
                    'texto_original': self.chunks_originais[i],
                    'similaridade': sim
                })
        
        # Ordenar por similaridade
        resultados.sort(key=lambda x: x['similaridade'], reverse=True)
        
        return resultados[:self.top_k]
    
    def gerar_resposta(self, pergunta, resultados):
        """Gera resposta baseada nos resultados da busca"""
        if not resultados:
            return "Desculpe, nÃ£o encontrei informaÃ§Ãµes relevantes sobre sua pergunta no texto de 'O Guarani'."
        
        # Usar o chunk mais relevante como base da resposta
        melhor_resultado = resultados[0]
        texto_base = melhor_resultado['texto_original']
        confianca = melhor_resultado['similaridade']
        
        # FormataÃ§Ã£o da resposta
        resposta = f"Com base em 'O Guarani':\n\n{texto_base}"
        
        # Adicionar indicador de confianÃ§a
        if confianca > 0.5:
            resposta += "\n\n(Resposta com alta confianÃ§a)"
        elif confianca > 0.3:
            resposta += "\n\n(Resposta com confianÃ§a moderada)"
        else:
            resposta += "\n\n(Resposta com baixa confianÃ§a)"
        
        return resposta

# Instanciar sistema de busca
sistema_busca = SistemaBusca(chunks, chunks_processados, vectorizador, matriz_vetores)

log_execucao("FASE4", "Sistema de busca implementado", True)

# %%
# Testar sistema com perguntas exemplo
log_execucao("FASE4", "Testando sistema com perguntas exemplo")

perguntas_teste = [
    "Quem Ã© Peri?",
    "Fale sobre CecÃ­lia",
    "Qual Ã© o enredo de O Guarani?",
    "Quem sÃ£o os personagens principais?",
    "Onde se passa a histÃ³ria?",
    "Como Ã© descrita a natureza no livro?"
]

resultados_teste = []

print("ðŸ§ª TESTE DO SISTEMA DE BUSCA")
print("=" * 50)

for pergunta in perguntas_teste:
    print(f"\nâ“ Pergunta: {pergunta}")
    
    # Buscar
    resultados = sistema_busca.buscar(pergunta)
    
    # Gerar resposta
    resposta = sistema_busca.gerar_resposta(pergunta, resultados)
    
    # Exibir resultado resumido
    if resultados:
        sim_max = max([r['similaridade'] for r in resultados])
        print(f"ðŸŽ¯ Similaridade mÃ¡xima: {sim_max:.3f}")
        print(f"ðŸ“ Chunks encontrados: {len(resultados)}")
        print(f"ðŸ¤– Resposta: {resposta[:100]}...")
    else:
        print("âŒ Nenhum resultado encontrado")
    
    # Armazenar para histÃ³rico
    resultados_teste.append({
        'pergunta': pergunta,
        'resposta': resposta,
        'num_resultados': len(resultados),
        'similaridade_max': max([r['similaridade'] for r in resultados]) if resultados else 0
    })

log_execucao("FASE4", f"Teste concluÃ­do com {len(perguntas_teste)} perguntas", len(perguntas_teste))

# %% [markdown]
# ## ðŸŽ¯ Fase 5: Interface e DemonstraÃ§Ã£o

# %%
log_execucao("FASE5", "Preparando interface de demonstraÃ§Ã£o")

def demonstrar_consulta_detalhada(pergunta):
    """Demonstra uma consulta com detalhes completos"""
    print(f"ðŸ” ANÃLISE DETALHADA DA CONSULTA")
    print("=" * 60)
    print(f"Pergunta: {pergunta}")
    print()
    
    # Buscar resultados
    resultados = sistema_busca.buscar(pergunta)
    
    # Mostrar processo de busca
    pergunta_processada = sistema_busca.processador.preprocessar(pergunta)
    print(f"Pergunta processada: {pergunta_processada}")
    print()
    
    # Mostrar resultados encontrados
    print(f"Resultados encontrados: {len(resultados)}")
    print()
    
    for i, resultado in enumerate(resultados):
        print(f"ðŸ“„ Resultado {i+1}:")
        print(f"   Similaridade: {resultado['similaridade']:.3f}")
        print(f"   Texto: {resultado['texto_original'][:200]}...")
        print()
    
    # Gerar e mostrar resposta final
    resposta = sistema_busca.gerar_resposta(pergunta, resultados)
    print("ðŸ¤– RESPOSTA FINAL:")
    print("=" * 40)
    print(resposta)
    
    return resposta

# DemonstraÃ§Ã£o com pergunta especÃ­fica
pergunta_demo = "Quem Ã© Peri e quais sÃ£o suas principais caracterÃ­sticas?"
resposta_demo = demonstrar_consulta_detalhada(pergunta_demo)

log_execucao("FASE5", "DemonstraÃ§Ã£o detalhada concluÃ­da", True)

# %% [markdown]
# ## ðŸ“Š AnÃ¡lise de Performance e HistÃ³rico

# %%
log_execucao("ANÃLISE", "Gerando estatÃ­sticas do sistema")

# EstatÃ­sticas gerais
print("ðŸ“ˆ ESTATÃSTICAS DO SISTEMA")
print("=" * 50)
print(f"Total de chunks: {len(chunks)}")
print(f"VocabulÃ¡rio: {len(vectorizador.vocabulary_)} termos")
print(f"DimensÃµes da matriz: {matriz_vetores.shape}")
print(f"Densidade da matriz: {matriz_vetores.nnz / (matriz_vetores.shape[0] * matriz_vetores.shape[1]):.3f}")

# AnÃ¡lise dos testes
if resultados_teste:
    similaridades = [r['similaridade_max'] for r in resultados_teste]
    print(f"\nPerguntas testadas: {len(resultados_teste)}")
    print(f"Similaridade mÃ©dia: {np.mean(similaridades):.3f}")
    print(f"Similaridade mÃ¡xima: {np.max(similaridades):.3f}")
    print(f"Similaridade mÃ­nima: {np.min(similaridades):.3f}")

log_execucao("ANÃLISE", "EstatÃ­sticas geradas", len(resultados_teste))

# %%
# VisualizaÃ§Ã£o das similaridades
log_execucao("ANÃLISE", "Criando visualizaÃ§Ãµes")

if resultados_teste:
    plt.figure(figsize=(12, 6))
    
    # GrÃ¡fico de barras das similaridades
    plt.subplot(1, 2, 1)
    perguntas_abrev = [r['pergunta'][:20] + "..." for r in resultados_teste]
    similaridades = [r['similaridade_max'] for r in resultados_teste]
    
    plt.bar(range(len(similaridades)), similaridades)
    plt.title('Similaridade por Pergunta')
    plt.xlabel('Pergunta')
    plt.ylabel('Similaridade MÃ¡xima')
    plt.xticks(range(len(perguntas_abrev)), perguntas_abrev, rotation=45, ha='right')
    
    # Histograma das similaridades
    plt.subplot(1, 2, 2)
    plt.hist(similaridades, bins=5, alpha=0.7, color='skyblue', edgecolor='black')
    plt.title('DistribuiÃ§Ã£o das Similaridades')
    plt.xlabel('Similaridade')
    plt.ylabel('FrequÃªncia')
    
    plt.tight_layout()
    plt.show()
    
    log_execucao("ANÃLISE", "VisualizaÃ§Ãµes criadas", True)

# %%
# HistÃ³rico completo de execuÃ§Ã£o
log_execucao("HISTÃ“RICO", "Compilando histÃ³rico completo")

print("ðŸ“‹ HISTÃ“RICO COMPLETO DE EXECUÃ‡ÃƒO")
print("=" * 70)

# Agrupar por fase
fases = {}
for entrada in historico_execucao:
    fase = entrada['fase']
    if fase not in fases:
        fases[fase] = []
    fases[fase].append(entrada)

# Exibir por fase
for fase, entradas in fases.items():
    print(f"\nðŸ”¹ {fase}:")
    for entrada in entradas:
        status = "âœ…" if entrada['status'] == 'OK' else "â³" if entrada['status'] == 'EXECUTANDO' else "âŒ"
        resultado_texto = f" â†’ {entrada['resultado']}" if entrada['resultado'] is not None else ""
        print(f"   [{entrada['timestamp']}] {status} {entrada['acao']}{resultado_texto}")

# Resumo final
total_acoes = len(historico_execucao)
acoes_ok = len([e for e in historico_execucao if e['status'] == 'OK'])
percentual_sucesso = (acoes_ok / total_acoes) * 100 if total_acoes > 0 else 0

print(f"\nðŸ“Š RESUMO FINAL:")
print(f"   Total de aÃ§Ãµes: {total_acoes}")
print(f"   AÃ§Ãµes bem-sucedidas: {acoes_ok}")
print(f"   Taxa de sucesso: {percentual_sucesso:.1f}%")

log_execucao("HISTÃ“RICO", "HistÃ³rico compilado", total_acoes)

# %% [markdown]
# ## ðŸŽ‰ Sistema Completo Implementado
# 
# O chatbot "O Guarani" foi implementado com sucesso seguindo todas as 5 fases:
# 
# 1. âœ… **PreparaÃ§Ã£o do Ambiente**: Bibliotecas configuradas
# 2. âœ… **Processamento dos Dados**: Texto limpo e segmentado em chunks
# 3. âœ… **Armazenamento e IndexaÃ§Ã£o**: Vetores TF-IDF criados
# 4. âœ… **Sistema de Busca**: Busca por similaridade implementada
# 5. âœ… **Interface**: Sistema testado e demonstrado
# 
# ### PrÃ³ximos Passos:
# - Expandir base de texto com obra completa
# - Implementar Word2Vec para melhor semÃ¢ntica
# - Adicionar interface web com Streamlit
# - Melhorar geraÃ§Ã£o de respostas com templates
# - Adicionar avaliaÃ§Ã£o automÃ¡tica de qualidade

print("\nðŸŽ‰ SISTEMA CHATBOT 'O GUARANI' IMPLEMENTADO COM SUCESSO!")
print("Todas as fases foram executadas e testadas.")
print("HistÃ³rico completo de execuÃ§Ã£o mantido e disponÃ­vel.")
