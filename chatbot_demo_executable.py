#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Chatbot "O Guarani" - Demonstra√ß√£o Pr√°tica das Melhorias Implementadas
Vers√£o execut√°vel para teste e valida√ß√£o
"""

import numpy as np
import re
from datetime import datetime
from typing import List, Dict, Tuple

class GuaraniChatbotDemo:
    """
    Demonstra√ß√£o pr√°tica do Chatbot O Guarani com todas as melhorias implementadas
    """
    
    def __init__(self):
        print("üöÄ Inicializando Chatbot O Guarani (Vers√£o Melhorada)")
        print("=" * 60)
        
        # Configura√ß√µes otimizadas baseadas nas sugest√µes
        self.chunk_size = 150      # ‚úÖ Reduzido de 250 para 150 palavras
        self.overlap = 0.3         # ‚úÖ Ajustado de 0.5 para 0.3
        self.similarity_threshold = 0.15  # ‚úÖ Aumentado de 0.05 para 0.15
        self.top_chunks = 3
        self.sentence_level_search = True  # ‚úÖ Nova funcionalidade
        
        # Stop words em portugu√™s (reintroduzidas)
        self.stop_words = {
            'a', 'o', 'e', 'de', 'da', 'do', 'em', 'um', 'uma', 'com', 'para',
            'por', 'que', 'se', 'na', 'no', 'ao', 'aos', 'as', 'os', 'mais',
            'mas', 'ou', 'ter', 'ser', 'estar', 'seu', 'sua', 'seus', 'suas',
            'foi', 's√£o', 'dos', 'das', 'pela', 'pelo', 'sobre', 'at√©', 'sem',
            'muito', 'bem', 'j√°', 'ainda', 's√≥', 'pode', 'tem', 'vai', 'vem'
        }
        
        # Texto expandido para demonstra√ß√£o
        self.texto_guarani = """
        O Guarani √© um romance indianista de Jos√© de Alencar, publicado em 1857. A narrativa se desenvolve no s√©culo XVII, 
        durante o per√≠odo colonial brasileiro, nas montanhas fluminenses pr√≥ximas ao rio Paquequer.
        
        Peri √© o protagonista da obra, um √≠ndio goitac√° de for√ßa herc√∫lea e lealdade inabal√°vel. Ele √© descrito como um 
        guerreiro corajoso, de estatura imponente e car√°ter nobre. Peri demonstra uma devo√ß√£o absoluta a Cec√≠lia (Ceci), 
        filha do fidalgo portugu√™s Dom Ant√¥nio de Mariz. Esta devo√ß√£o representa o amor imposs√≠vel entre duas ra√ßas distintas.
        
        Cec√≠lia, chamada carinhosamente de Ceci, √© uma jovem portuguesa de beleza singular e car√°ter doce. Ela √© filha 
        de Dom Ant√¥nio de Mariz e representa a pureza e a inoc√™ncia feminina idealizadas pelo Romantismo. Ceci desenvolve 
        sentimentos fraternais por Peri, vendo nele um protetor dedicado.
        
        Dom Ant√¥nio de Mariz √© um nobre portugu√™s, fidalgo da Casa Real, que se estabeleceu no Brasil ap√≥s cometer um crime 
        de honra em Portugal. Ele construiu um castelo fortificado nas margens do rio Paquequer, onde vive com sua fam√≠lia. 
        Dom Ant√¥nio √© caracterizado como um homem honrado, mas marcado pelo passado.
        
        Dona Lauriana √© a esposa de Dom Ant√¥nio, uma senhora portuguesa de origem nobre. Ela representa os valores 
        aristocr√°ticos europeus e inicialmente demonstra preconceito em rela√ß√£o aos ind√≠genas.
        
        √Ålvaro √© um jovem portugu√™s, primo de Cec√≠lia, que tamb√©m habita o castelo. Ele encarna o ideal do cavaleiro 
        medieval, sendo corajoso, nobre e apaixonado por Ceci. √Ålvaro representa a civiliza√ß√£o europeia em contraste 
        com a natureza selvagem de Peri.
        
        Isabel √© irm√£ de Cec√≠lia, uma jovem impetuosa e apaixonada. Ela se enamora de √Ålvaro, criando um tri√¢ngulo 
        amoroso que adiciona complexidade √†s rela√ß√µes familiares. Isabel possui um temperamento mais forte que sua irm√£.
        
        Loredano √© um dos antagonistas da hist√≥ria, um aventureiro italiano que se infiltra no castelo com inten√ß√µes 
        mal√©volas. Ele planeja assassinar Dom Ant√¥nio e se apossar de suas riquezas, representando a trai√ß√£o e a vilania.
        
        Os aimor√©s s√£o a tribo ind√≠gena antagonista, inimigos mortais de Peri e de sua tribo goitac√°. Eles representam 
        o perigo constante que amea√ßa a seguran√ßa dos habitantes do castelo. Os aimor√©s s√£o descritos como selvagens 
        e canibais, contrastando com a nobreza de Peri.
        
        A natureza brasileira desempenha papel fundamental na narrativa, sendo descrita com exuber√¢ncia e riqueza de 
        detalhes. Alencar retrata as florestas, rios e montanhas como cen√°rio √©pico que reflete o car√°ter dos personagens. 
        A paisagem tropical serve como pano de fundo para os conflitos entre civiliza√ß√£o e barb√°rie.
        
        O romance explora temas centrais como o amor imposs√≠vel entre ra√ßas diferentes, representado pela rela√ß√£o entre 
        Peri e Ceci. A lealdade e o sacrif√≠cio s√£o exemplificados pela devo√ß√£o absoluta do √≠ndio √† fam√≠lia Mariz. 
        O choque entre civiliza√ß√µes aparece no contraste entre os valores europeus e ind√≠genas.
        
        A linguagem de Alencar combina o portugu√™s erudito com tentativas de recriar a fala ind√≠gena, criando um estilo 
        √∫nico que busca expressar a realidade brasileira. O autor emprega descri√ß√µes rom√¢nticas e idealizadas tanto 
        dos personagens quanto da natureza.
        
        O desfecho tr√°gico da obra culmina com a destrui√ß√£o do castelo e a fuga de Peri e Ceci, simbolizando o nascimento 
        de uma nova ra√ßa brasileira atrav√©s da uni√£o simb√≥lica entre o √≠ndio e a portuguesa. Esta uni√£o representa a 
        forma√ß√£o da identidade nacional brasileira segundo a vis√£o rom√¢ntica de Alencar.
        """
        
        # Estruturas de dados
        self.text_chunks = []
        self.chunk_sentences = []  # Nova: senten√ßas por chunk
        self.conversation_history = []
        self.processing_log = []
        self.performance_metrics = []
        
        print("‚úÖ Configura√ß√£o inicial conclu√≠da")
    
    def log_evento(self, message: str):
        """Registra eventos com timestamp"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        self.processing_log.append(log_entry)
        print(f"üìù {log_entry}")
    
    def fase1_analise_texto(self):
        """
        Fase 1: An√°lise detalhada do texto
        Melhoria: An√°lise estat√≠stica mais completa
        """
        self.log_evento("=== FASE 1: AN√ÅLISE AVAN√áADA DO TEXTO ===")
        
        # Estat√≠sticas b√°sicas
        chars = len(self.texto_guarani)
        words = self.texto_guarani.split()
        
        # An√°lise de senten√ßas
        sentences = re.split(r'[.!?]+', self.texto_guarani)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # An√°lise de vocabul√°rio
        word_tokens = re.findall(r'\b\w+\b', self.texto_guarani.lower())
        unique_words = set(word_tokens)
        content_words = unique_words - self.stop_words
        
        # Relat√≥rio detalhado
        stats = {
            "Caracteres totais": chars,
            "Palavras totais": len(words),
            "Senten√ßas": len(sentences),
            "Vocabul√°rio √∫nico": len(unique_words),
            "Palavras de conte√∫do": len(content_words),
            "Densidade lexical": f"{len(content_words)/len(unique_words)*100:.1f}%",
            "M√©dia palavras/senten√ßa": f"{len(words)/len(sentences):.1f}"
        }
        
        for key, value in stats.items():
            self.log_evento(f"{key}: {value}")
        
        return True
    
    def fase2_chunking_otimizado(self):
        """
        Fase 2: Cria√ß√£o de chunks otimizada
        Melhorias: Tamanho reduzido, melhor sobreposi√ß√£o, mapeamento de senten√ßas
        """
        self.log_evento("=== FASE 2: CHUNKING OTIMIZADO ===")
        
        # Limpeza do texto preservando estrutura
        text = re.sub(r'\n+', ' ', self.texto_guarani)
        text = re.sub(r'\s+', ' ', text).strip()
        
        # Segmenta√ß√£o em senten√ßas
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # Cria√ß√£o de chunks com sobreposi√ß√£o otimizada
        chunks = []
        chunk_sentences_map = []
        current_chunk_sentences = []
        current_word_count = 0
        
        for sentence in sentences:
            words = sentence.split()
            sentence_word_count = len(words)
            
            # Verificar se cabe no chunk atual
            if current_word_count + sentence_word_count <= self.chunk_size:
                current_chunk_sentences.append(sentence)
                current_word_count += sentence_word_count
            else:
                # Finalizar chunk atual
                if current_chunk_sentences:
                    chunk_text = '. '.join(current_chunk_sentences) + '.'
                    chunks.append(chunk_text)
                    chunk_sentences_map.append(current_chunk_sentences.copy())
                
                # Calcular sobreposi√ß√£o
                overlap_size = int(len(current_chunk_sentences) * self.overlap)
                if overlap_size > 0 and len(current_chunk_sentences) > overlap_size:
                    current_chunk_sentences = current_chunk_sentences[-overlap_size:]
                    current_word_count = sum(len(s.split()) for s in current_chunk_sentences)
                else:
                    current_chunk_sentences = []
                    current_word_count = 0
                
                # Adicionar nova senten√ßa
                current_chunk_sentences.append(sentence)
                current_word_count += sentence_word_count
        
        # Finalizar √∫ltimo chunk
        if current_chunk_sentences:
            chunk_text = '. '.join(current_chunk_sentences) + '.'
            chunks.append(chunk_text)
            chunk_sentences_map.append(current_chunk_sentences.copy())
        
        self.text_chunks = chunks
        self.chunk_sentences = chunk_sentences_map
        
        # Estat√≠sticas dos chunks
        chunk_sizes = [len(chunk.split()) for chunk in chunks]
        self.log_evento(f"Chunks criados: {len(chunks)}")
        self.log_evento(f"Tamanho m√©dio: {np.mean(chunk_sizes):.1f} palavras")
        self.log_evento(f"Tamanho m√≠nimo: {min(chunk_sizes)} palavras")
        self.log_evento(f"Tamanho m√°ximo: {max(chunk_sizes)} palavras")
        
        return True
    
    def calcular_similaridade_melhorada(self, pergunta: str, texto: str) -> float:
        """
        C√°lculo de similaridade melhorado
        Melhorias: Remo√ß√£o de stop words, bonus para matches importantes
        """
        # Preprocessamento da pergunta
        pergunta_words = set(re.findall(r'\b\w+\b', pergunta.lower()))
        pergunta_content = pergunta_words - self.stop_words
        
        # Preprocessamento do texto
        texto_words = set(re.findall(r'\b\w+\b', texto.lower()))
        texto_content = texto_words - self.stop_words
        
        # Similaridade Jaccard b√°sica
        intersection = len(pergunta_content & texto_content)
        union = len(pergunta_content | texto_content)
        jaccard_sim = intersection / union if union > 0 else 0
        
        # Bonus para palavras-chave importantes
        important_words = pergunta_content - {'quem', 'qual', 'onde', 'como', 'quando', 'sobre', 'fale', 'conte'}
        exact_matches = len(important_words & texto_content)
        bonus = min(exact_matches * 0.1, 0.3)  # M√°ximo 30% de bonus
        
        # Penalty para textos muito curtos
        min_content_size = min(len(pergunta_content), len(texto_content))
        if min_content_size < 3:
            penalty = 0.2
        else:
            penalty = 0
        
        final_similarity = max(0, min(1.0, jaccard_sim + bonus - penalty))
        return final_similarity
    
    def fase3_busca_nivel_sentenca(self, pergunta: str, chunk_id: int) -> Dict:
        """
        Fase 3: Busca refinada no n√≠vel de senten√ßa
        Melhoria: Localizar a senten√ßa mais relevante dentro do chunk
        """
        chunk = self.text_chunks[chunk_id]
        sentences = self.chunk_sentences[chunk_id]
        
        # Calcular similaridade para cada senten√ßa
        sentence_scores = []
        for i, sentence in enumerate(sentences):
            similarity = self.calcular_similaridade_melhorada(pergunta, sentence)
            sentence_scores.append({
                'sentence_id': i,
                'sentence': sentence,
                'similarity': similarity
            })
        
        # Encontrar melhor senten√ßa
        best_sentence = max(sentence_scores, key=lambda x: x['similarity'])
        chunk_similarity = self.calcular_similaridade_melhorada(pergunta, chunk)
        
        return {
            'chunk_id': chunk_id,
            'chunk': chunk,
            'chunk_similarity': chunk_similarity,
            'best_sentence': best_sentence,
            'all_sentences': sentence_scores
        }
    
    def fase4_resposta_inteligente(self, pergunta: str) -> str:
        """
        Fase 4: Gera√ß√£o de resposta inteligente
        Melhorias: Threshold mais alto, busca por senten√ßa, confian√ßa melhorada
        """
        start_time = datetime.now()
        self.log_evento(f"=== CONSULTA: {pergunta} ===")
        
        if not self.text_chunks:
            return "‚ùå Sistema n√£o processado. Execute as fases anteriores."
        
        # Calcular scores para todos os chunks
        chunk_results = []
        for i, chunk in enumerate(self.text_chunks):
            if self.sentence_level_search:
                result = self.fase3_busca_nivel_sentenca(pergunta, i)
            else:
                similarity = self.calcular_similaridade_melhorada(pergunta, chunk)
                result = {
                    'chunk_id': i,
                    'chunk': chunk,
                    'chunk_similarity': similarity,
                    'best_sentence': None
                }
            chunk_results.append(result)
        
        # Ordenar por similaridade
        chunk_results.sort(key=lambda x: x['chunk_similarity'], reverse=True)
        
        # Estat√≠sticas
        similarities = [r['chunk_similarity'] for r in chunk_results]
        max_sim = max(similarities) if similarities else 0
        mean_sim = np.mean(similarities) if similarities else 0
        
        self.log_evento(f"Similaridade m√°xima: {max_sim:.3f}")
        self.log_evento(f"Similaridade m√©dia: {mean_sim:.3f}")
        
        # Filtrar resultados relevantes com threshold mais alto
        relevant_results = [
            result for result in chunk_results 
            if result['chunk_similarity'] >= self.similarity_threshold
        ]
        
        self.log_evento(f"Chunks relevantes encontrados: {len(relevant_results)}")
        
        # Gerar resposta
        if not relevant_results:
            response = self._resposta_nao_encontrada(pergunta, max_sim)
        else:
            response = self._gerar_resposta_otimizada(pergunta, relevant_results[:self.top_chunks])
        
        # M√©tricas de performance
        processing_time = (datetime.now() - start_time).total_seconds()
        self.performance_metrics.append({
            'pergunta': pergunta,
            'tempo_processamento': processing_time,
            'max_similarity': max_sim,
            'chunks_relevantes': len(relevant_results),
            'timestamp': datetime.now()
        })
        
        # Hist√≥rico expandido
        self.conversation_history.append({
            'pergunta': pergunta,
            'resposta': response,
            'similaridade_max': max_sim,
            'chunks_usados': len(relevant_results),
            'tempo_resposta': processing_time,
            'timestamp': datetime.now()
        })
        
        self.log_evento(f"Resposta gerada em {processing_time:.3f}s")
        return response
    
    def _resposta_nao_encontrada(self, pergunta: str, max_sim: float) -> str:
        """Resposta otimizada quando n√£o encontra informa√ß√µes"""
        base_msg = "N√£o encontrei informa√ß√µes espec√≠ficas sobre sua pergunta no texto de 'O Guarani'."
        
        if max_sim > 0.1:
            suggestion = "\n\nüí° Sugest√£o: Tente reformular usando termos mais pr√≥ximos aos do texto original."
        elif max_sim > 0.05:
            suggestion = "\n\nüí° Sugest√£o: Use nomes espec√≠ficos de personagens ou eventos da obra."
        else:
            suggestion = "\n\nüí° Sugest√£o: Sua pergunta pode estar fora do escopo da obra."
        
        examples = """
\nüìù Exemplos de perguntas eficazes:
‚Ä¢ "Quem √© Peri?" ou "Fale sobre Peri"
‚Ä¢ "Quem √© Cec√≠lia?" ou "Descreva Ceci"
‚Ä¢ "Qual a rela√ß√£o entre Peri e Cec√≠lia?"
‚Ä¢ "Quem s√£o os aimor√©s?"
‚Ä¢ "Onde se passa a hist√≥ria?"
‚Ä¢ "Quem √© Dom Ant√¥nio de Mariz?"
"""
        
        confidence = f"\n\nüî¥ Confian√ßa muito baixa (max. similaridade: {max_sim:.3f})"
        
        return base_msg + suggestion + examples + confidence
    
    def _gerar_resposta_otimizada(self, pergunta: str, results: List[Dict]) -> str:
        """Gera√ß√£o de resposta com busca por senten√ßa"""
        if not results:
            return self._resposta_nao_encontrada(pergunta, 0)
        
        best_result = results[0]
        
        # Se temos busca por senten√ßa e uma boa senten√ßa foi encontrada
        if (self.sentence_level_search and 
            best_result.get('best_sentence') and 
            best_result['best_sentence']['similarity'] > 0.2):
            
            best_sentence = best_result['best_sentence']['sentence']
            sentence_sim = best_result['best_sentence']['similarity']
            
            # Adicionar contexto se necess√°rio
            if len(results) > 1 and results[1]['chunk_similarity'] > 0.2:
                context_chunk = results[1]['chunk']
                if len(context_chunk) < 200:
                    additional_info = f"\n\nInforma√ß√£o adicional: {context_chunk}"
                else:
                    additional_info = f"\n\nInforma√ß√£o adicional: {context_chunk[:200]}..."
            else:
                additional_info = ""
            
            confidence = self._calcular_indicador_confianca(sentence_sim)
            
            response = f"Com base em 'O Guarani':\n\n{best_sentence}{additional_info}\n\n{confidence}"
            
        else:
            # Resposta baseada em chunk completo
            if len(results) == 1:
                main_content = results[0]['chunk']
                intro = "Com base no texto de 'O Guarani':\n\n"
            else:
                combined_content = ". ".join([r['chunk'] for r in results[:2]])
                main_content = combined_content
                intro = "Combinando informa√ß√µes de 'O Guarani':\n\n"
            
            # Truncar se muito longo
            if len(main_content) > 600:
                main_content = main_content[:600] + "..."
            
            confidence = self._calcular_indicador_confianca(best_result['chunk_similarity'])
            response = intro + main_content + "\n\n" + confidence
        
        return response
    
    def _calcular_indicador_confianca(self, similarity: float) -> str:
        """Indicadores de confian√ßa mais precisos"""
        if similarity > 0.6:
            return "üü¢ Confian√ßa muito alta"
        elif similarity > 0.4:
            return "üü¢ Confian√ßa alta"
        elif similarity > 0.25:
            return "üü° Confian√ßa moderada"
        elif similarity > 0.15:
            return "üü† Confian√ßa baixa - considere reformular"
        else:
            return "üî¥ Confian√ßa muito baixa"
    
    def mostrar_estatisticas_completas(self):
        """Estat√≠sticas detalhadas do sistema"""
        print("\nüìä ESTAT√çSTICAS COMPLETAS DO SISTEMA")
        print("=" * 60)
        
        # Configura√ß√µes
        print("üîß CONFIGURA√á√ïES:")
        print(f"   ‚Ä¢ Tamanho dos chunks: {self.chunk_size} palavras")
        print(f"   ‚Ä¢ Sobreposi√ß√£o: {self.overlap * 100}%")
        print(f"   ‚Ä¢ Threshold de similaridade: {self.similarity_threshold}")
        print(f"   ‚Ä¢ Busca por senten√ßa: {'Ativada' if self.sentence_level_search else 'Desativada'}")
        print(f"   ‚Ä¢ Stop words removidas: {len(self.stop_words)}")
        
        # Dados processados
        print(f"\nüìö DADOS PROCESSADOS:")
        print(f"   ‚Ä¢ Total de chunks: {len(self.text_chunks)}")
        if self.text_chunks:
            chunk_sizes = [len(chunk.split()) for chunk in self.text_chunks]
            print(f"   ‚Ä¢ Tamanho m√©dio dos chunks: {np.mean(chunk_sizes):.1f} palavras")
            print(f"   ‚Ä¢ Menor chunk: {min(chunk_sizes)} palavras")
            print(f"   ‚Ä¢ Maior chunk: {max(chunk_sizes)} palavras")
        
        # Hist√≥rico de consultas
        print(f"\nüí¨ HIST√ìRICO DE CONSULTAS:")
        print(f"   ‚Ä¢ Total de consultas: {len(self.conversation_history)}")
        
        if self.performance_metrics:
            tempos = [m['tempo_processamento'] for m in self.performance_metrics]
            similarities = [m['max_similarity'] for m in self.performance_metrics]
            
            print(f"   ‚Ä¢ Tempo m√©dio de resposta: {np.mean(tempos):.3f}s")
            print(f"   ‚Ä¢ Tempo m√≠nimo: {min(tempos):.3f}s")
            print(f"   ‚Ä¢ Tempo m√°ximo: {max(tempos):.3f}s")
            print(f"   ‚Ä¢ Similaridade m√©dia: {np.mean(similarities):.3f}")
            print(f"   ‚Ä¢ Melhor similaridade: {max(similarities):.3f}")
        
        # Qualidade das respostas
        if self.conversation_history:
            print(f"\nüéØ QUALIDADE DAS RESPOSTAS:")
            alta_confianca = sum(1 for c in self.conversation_history if c['similaridade_max'] > 0.4)
            media_confianca = sum(1 for c in self.conversation_history if 0.2 <= c['similaridade_max'] <= 0.4)
            baixa_confianca = sum(1 for c in self.conversation_history if c['similaridade_max'] < 0.2)
            
            total = len(self.conversation_history)
            print(f"   ‚Ä¢ Alta confian√ßa: {alta_confianca}/{total} ({alta_confianca/total*100:.1f}%)")
            print(f"   ‚Ä¢ M√©dia confian√ßa: {media_confianca}/{total} ({media_confianca/total*100:.1f}%)")
            print(f"   ‚Ä¢ Baixa confian√ßa: {baixa_confianca}/{total} ({baixa_confianca/total*100:.1f}%)")
    
    def mostrar_historico_detalhado(self):
        """Hist√≥rico detalhado das conversas"""
        if not self.conversation_history:
            print("üì≠ Nenhuma conversa no hist√≥rico.")
            return
        
        print(f"\nüìö HIST√ìRICO DETALHADO ({len(self.conversation_history)} conversas)")
        print("=" * 70)
        
        for i, conv in enumerate(self.conversation_history, 1):
            timestamp = conv['timestamp'].strftime("%H:%M:%S")
            print(f"\n{i}. [{timestamp}] {conv['pergunta']}")
            print(f"   ‚è±Ô∏è  Tempo: {conv['tempo_resposta']:.3f}s")
            print(f"   üìä Similaridade: {conv['similaridade_max']:.3f}")
            print(f"   üìù Chunks usados: {conv['chunks_usados']}")
            print(f"   üí≠ Resposta: {conv['resposta'][:100]}...")
    
    def executar_testes_abrangentes(self):
        """Testes autom√°ticos abrangentes do sistema"""
        perguntas_teste = [
            # Personagens principais
            "Quem √© Peri?",
            "Fale sobre Cec√≠lia",
            "Quem √© Dom Ant√¥nio de Mariz?",
            "Descreva √Ålvaro",
            
            # Relacionamentos
            "Qual a rela√ß√£o entre Peri e Cec√≠lia?",
            "Quem Isabel ama?",
            
            # Antagonistas
            "Quem s√£o os aimor√©s?",
            "Fale sobre Loredano",
            
            # Contexto e temas
            "Onde se passa a hist√≥ria?",
            "Quando foi publicado O Guarani?",
            "Quais s√£o os temas da obra?",
            "Como √© descrita a natureza?",
            
            # Perguntas mais espec√≠ficas
            "Por que Dom Ant√¥nio veio ao Brasil?",
            "O que representa Peri na obra?",
            
            # Perguntas que devem ter baixa similaridade
            "Qual a receita do bolo de chocolate?",
            "Como funciona um computador?"
        ]
        
        print(f"\nüß™ EXECUTANDO TESTES ABRANGENTES ({len(perguntas_teste)} perguntas)")
        print("=" * 70)
        
        resultados = []
        
        for i, pergunta in enumerate(perguntas_teste, 1):
            print(f"\nüìã Teste {i:2d}/{len(perguntas_teste)}: {pergunta}")
            
            start_time = datetime.now()
            resposta = self.fase4_resposta_inteligente(pergunta)
            tempo_total = (datetime.now() - start_time).total_seconds()
            
            # Analisar qualidade da resposta
            ultimo_historico = self.conversation_history[-1]
            qualidade = self._avaliar_qualidade_resposta(ultimo_historico['similaridade_max'])
            
            resultado = {
                'numero': i,
                'pergunta': pergunta,
                'tempo': tempo_total,
                'similaridade': ultimo_historico['similaridade_max'],
                'chunks_usados': ultimo_historico['chunks_usados'],
                'qualidade': qualidade
            }
            resultados.append(resultado)
            
            print(f"   ‚è±Ô∏è  {tempo_total:.3f}s | üìä {ultimo_historico['similaridade_max']:.3f} | {qualidade}")
            
            # Mostrar in√≠cio da resposta para perguntas relevantes
            if ultimo_historico['similaridade_max'] > 0.1:
                print(f"   üí¨ {resposta[:80]}...")
        
        # Relat√≥rio final dos testes
        self._gerar_relatorio_final_testes(resultados)
        
        return resultados
    
    def _avaliar_qualidade_resposta(self, similaridade: float) -> str:
        """Avalia qualidade baseada na similaridade"""
        if similaridade > 0.4:
            return "üü¢ Excelente"
        elif similaridade > 0.25:
            return "üü° Boa"
        elif similaridade > 0.15:
            return "üü† Regular"
        elif similaridade > 0.05:
            return "üî¥ Ruim"
        else:
            return "‚ùå Irrelevante"
    
    def _gerar_relatorio_final_testes(self, resultados: List[Dict]):
        """Relat√≥rio detalhado dos testes"""
        print(f"\nüìã RELAT√ìRIO FINAL DOS TESTES")
        print("=" * 70)
        
        # M√©tricas gerais
        tempos = [r['tempo'] for r in resultados]
        similaridades = [r['similaridade'] for r in resultados]
        
        print(f"üìä M√âTRICAS GERAIS:")
        print(f"   ‚Ä¢ Testes executados: {len(resultados)}")
        print(f"   ‚Ä¢ Tempo total: {sum(tempos):.2f}s")
        print(f"   ‚Ä¢ Tempo m√©dio por pergunta: {np.mean(tempos):.3f}s")
        print(f"   ‚Ä¢ Tempo m√°ximo: {max(tempos):.3f}s")
        print(f"   ‚Ä¢ Similaridade m√©dia: {np.mean(similaridades):.3f}")
        print(f"   ‚Ä¢ Similaridade m√°xima: {max(similaridades):.3f}")
        print(f"   ‚Ä¢ Similaridade m√≠nima: {min(similaridades):.3f}")
        
        # Distribui√ß√£o de qualidade
        qualidades = [r['qualidade'] for r in resultados]
        excelentes = qualidades.count("üü¢ Excelente")
        boas = qualidades.count("üü° Boa")
        regulares = qualidades.count("üü† Regular")
        ruins = qualidades.count("üî¥ Ruim")
        irrelevantes = qualidades.count("‚ùå Irrelevante")
        
        total = len(resultados)
        print(f"\nüéØ DISTRIBUI√á√ÉO DE QUALIDADE:")
        print(f"   ‚Ä¢ Excelentes: {excelentes:2d}/{total} ({excelentes/total*100:5.1f}%)")
        print(f"   ‚Ä¢ Boas:       {boas:2d}/{total} ({boas/total*100:5.1f}%)")
        print(f"   ‚Ä¢ Regulares:  {regulares:2d}/{total} ({regulares/total*100:5.1f}%)")
        print(f"   ‚Ä¢ Ruins:      {ruins:2d}/{total} ({ruins/total*100:5.1f}%)")
        print(f"   ‚Ä¢ Irrelevantes: {irrelevantes:2d}/{total} ({irrelevantes/total*100:5.1f}%)")
        
        # Melhores e piores resultados
        resultados_ordenados = sorted(resultados, key=lambda x: x['similaridade'], reverse=True)
        
        print(f"\nüèÜ TOP 3 MELHORES RESULTADOS:")
        for i, resultado in enumerate(resultados_ordenados[:3], 1):
            print(f"   {i}. {resultado['pergunta'][:40]}... | {resultado['similaridade']:.3f}")
        
        print(f"\n‚ö†Ô∏è TOP 3 PIORES RESULTADOS:")
        for i, resultado in enumerate(resultados_ordenados[-3:], 1):
            print(f"   {i}. {resultado['pergunta'][:40]}... | {resultado['similaridade']:.3f}")
        
        # Recomenda√ß√µes
        taxa_sucesso = (excelentes + boas) / total
        print(f"\nüí° RECOMENDA√á√ïES:")
        
        if taxa_sucesso > 0.7:
            print("   ‚úÖ Sistema funcionando bem! Par√¢metros otimizados.")
        elif taxa_sucesso > 0.5:
            print("   üü° Sistema com performance razo√°vel. Considere ajustes nos par√¢metros.")
        else:
            print("   ‚ö†Ô∏è Sistema precisa de melhorias:")
            print("      - Verificar qualidade do texto de entrada")
            print("      - Ajustar threshold de similaridade")
            print("      - Revisar algoritmo de chunking")
        
        if np.mean(similaridades) < 0.2:
            print("   üìâ Similaridades baixas detectadas:")
            print("      - Verificar remo√ß√£o de stop words")
            print("      - Considerar t√©cnicas de normaliza√ß√£o textual")
            print("      - Avaliar algoritmo de similaridade")
    
    def executar_sistema_completo_melhorado(self):
        """Execu√ß√£o completa do sistema com todas as melhorias"""
        print("üöÄ EXECUTANDO SISTEMA COMPLETO COM MELHORIAS")
        print("=" * 70)
        
        try:
            # Fase 1: An√°lise do texto
            if not self.fase1_analise_texto():
                raise Exception("Falha na an√°lise do texto")
            
            # Fase 2: Chunking otimizado
            if not self.fase2_chunking_otimizado():
                raise Exception("Falha no processamento dos chunks")
            
            print("\n‚úÖ SISTEMA INICIALIZADO COM SUCESSO!")
            print("üéØ Todas as melhorias foram implementadas:")
            print("   ‚úÖ Threshold de similaridade aumentado para 0.15")
            print("   ‚úÖ Tamanho dos chunks reduzido para 150 palavras")
            print("   ‚úÖ Stop words reintroduzidas no processamento")
            print("   ‚úÖ Busca refinada no n√≠vel de senten√ßas")
            print("   ‚úÖ Sistema de confian√ßa melhorado")
            print("   ‚úÖ M√©tricas de performance expandidas")
            
            return True
            
        except Exception as e:
            self.log_evento(f"‚ùå Erro na execu√ß√£o: {e}")
            return False
    
    def interface_interativa_melhorada(self):
        """Interface de usu√°rio melhorada"""
        print("\n" + "="*70)
        print("ü§ñ CHATBOT O GUARANI - VERS√ÉO MELHORADA")
        print("Assistente especializado na obra de Jos√© de Alencar")
        print(f"Threshold: {self.similarity_threshold} | Chunks: {len(self.text_chunks)} | Busca: N√≠vel de senten√ßa")
        print("\nüìã Comandos dispon√≠veis:")
        print("   üí¨ Digite sua pergunta normalmente")
        print("   üìä 'stats' - Estat√≠sticas completas")
        print("   üìö 'historico' - Hist√≥rico detalhado")
        print("   üß™ 'teste' - Executar testes autom√°ticos")
        print("   ‚ùì 'ajuda' - Mostrar exemplos de perguntas")
        print("   üö™ 'sair' - Encerrar o sistema")
        print("="*70)
        
        while True:
            try:
                pergunta = input("\nüí¨ Sua pergunta: ").strip()
                
                if pergunta.lower() in ['sair', 'exit', 'quit']:
                    print("üëã At√© logo!")
                    break
                elif pergunta.lower() in ['stats', 'estatisticas', 'estat√≠sticas']:
                    self.mostrar_estatisticas_completas()
                    continue
                elif pergunta.lower() in ['historico', 'hist√≥rico', 'history']:
                    self.mostrar_historico_detalhado()
                    continue
                elif pergunta.lower() in ['teste', 'testes', 'test']:
                    self.executar_testes_abrangentes()
                    continue
                elif pergunta.lower() in ['ajuda', 'help', 'exemplos']:
                    self._mostrar_ajuda_detalhada()
                    continue
                
                if not pergunta:
                    print("‚ö†Ô∏è  Digite uma pergunta ou comando.")
                    continue
                
                # Processar pergunta
                resposta = self.fase4_resposta_inteligente(pergunta)
                print(f"\nü§ñ {resposta}")
                
            except KeyboardInterrupt:
                print("\nüëã Encerrando...")
                break
            except Exception as e:
                print(f"‚ùå Erro: {e}")
    
    def _mostrar_ajuda_detalhada(self):
        """Ajuda detalhada com exemplos"""
        help_text = """
üÜò AJUDA DETALHADA - CHATBOT O GUARANI

üìù TIPOS DE PERGUNTAS QUE FUNCIONAM BEM:

üßë Sobre personagens principais:
   ‚Ä¢ "Quem √© Peri?" / "Descreva Peri"
   ‚Ä¢ "Fale sobre Cec√≠lia" / "Quem √© Ceci?"
   ‚Ä¢ "Quem √© Dom Ant√¥nio de Mariz?"
   ‚Ä¢ "Descreva √Ålvaro"

üíï Sobre relacionamentos:
   ‚Ä¢ "Qual a rela√ß√£o entre Peri e Cec√≠lia?"
   ‚Ä¢ "Quem Isabel ama?"
   ‚Ä¢ "Por que Peri √© devotado √† Ceci?"

üè∞ Sobre contexto e cen√°rio:
   ‚Ä¢ "Onde se passa a hist√≥ria?"
   ‚Ä¢ "Quando foi publicado O Guarani?"
   ‚Ä¢ "Como √© o castelo de Dom Ant√¥nio?"

‚öîÔ∏è Sobre conflitos e antagonistas:
   ‚Ä¢ "Quem s√£o os aimor√©s?"
   ‚Ä¢ "Fale sobre Loredano"
   ‚Ä¢ "Quais s√£o os perigos na hist√≥ria?"

üé≠ Sobre temas e estilo:
   ‚Ä¢ "Quais s√£o os temas principais?"
   ‚Ä¢ "Como √© descrita a natureza?"
   ‚Ä¢ "O que a obra representa?"

üí° DICAS PARA MELHORES RESPOSTAS:
   ‚Ä¢ Use nomes espec√≠ficos de personagens
   ‚Ä¢ Seja direto e claro na pergunta
   ‚Ä¢ Reformule se a resposta n√£o for satisfat√≥ria
   ‚Ä¢ Perguntas sobre a obra t√™m melhor resultado que perguntas gerais

‚ö†Ô∏è EVITE:
   ‚Ä¢ Perguntas muito vagas ou gen√©ricas
   ‚Ä¢ Temas fora do escopo da obra
   ‚Ä¢ Perguntas sobre outros livros ou autores
        """
        print(help_text)

def main():
    """Fun√ß√£o principal para demonstra√ß√£o completa"""
    print("üéØ DEMONSTRA√á√ÉO COMPLETA DO CHATBOT O GUARANI MELHORADO")
    print("üìö Implementando todas as melhorias sugeridas no documento")
    print("=" * 80)
    
    # Criar inst√¢ncia do chatbot
    chatbot = GuaraniChatbotDemo()
    
    # Executar sistema completo
    if chatbot.executar_sistema_completo_melhorado():
        print("\nüéâ SISTEMA PRONTO PARA USO!")
        
        # Menu principal
        while True:
            print("\nüéØ MENU PRINCIPAL:")
            print("1. üí¨ Iniciar chat interativo")
            print("2. üß™ Executar testes autom√°ticos")
            print("3. üìä Ver estat√≠sticas do sistema")
            print("4. üìö Ver hist√≥rico (se houver)")
            print("5. ‚ùì Ver ajuda e exemplos")
            print("6. üö™ Sair")
            
            try:
                opcao = input("\nEscolha uma op√ß√£o (1-6): ").strip()
                
                if opcao == '1':
                    chatbot.interface_interativa_melhorada()
                elif opcao == '2':
                    chatbot.executar_testes_abrangentes()
                elif opcao == '3':
                    chatbot.mostrar_estatisticas_completas()
                elif opcao == '4':
                    chatbot.mostrar_historico_detalhado()
                elif opcao == '5':
                    chatbot._mostrar_ajuda_detalhada()
                elif opcao == '6':
                    print("üëã Encerrando sistema...")
                    break
                else:
                    print("‚ùå Op√ß√£o inv√°lida. Tente novamente.")
                    
            except KeyboardInterrupt:
                print("\nüëã Encerrando...")
                break
    else:
        print("‚ùå Falha na inicializa√ß√£o do sistema")

if __name__ == "__main__":
    main()